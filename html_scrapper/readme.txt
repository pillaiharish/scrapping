As of now crap.js is just an html local file scrapper. scrap.js would focus on requesting url before scrapping.
The scrapping process can be automated using selenium so that multiple links can be scraped.
the main file is crap.js #it may sound weird but this name came by duplicating scrap.js by removing s to rename it
the  dependencies are npm packages: 
fs,
cheerio,
requirejs,
request,
expressjs,
jsonframe-cheerio,

link for pseudo classes that are used to query
https://www.w3schools.com/css/css_pseudo_classes.asp

also pseudo elements can be used to enhance xpath
https://www.w3schools.com/css/css_pseudo_elements.asp
